{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4tRlK-8Q87v6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t = torchaudio.transforms.MelSpectrogram(sample_rate=48000, n_mels=128)\\npath = \"/content/COMMONVOICE\"\\nTSV = \"my_test.tsv\"\\n\\ntsvm = os.path.join(path, TSV)\\ndf = pd.read_csv(tsvm, sep=\"\\t\")\\nstrings = df[\\'path\\'].values\\nfolder = os.path.join(path, \"clips\")\\n\\nmel_l, wav_l = [], []\\ni = 0\\nprint(len(strings))\\nfor names in strings:\\n  filename = os.path.join(folder,names)\\n  waveform, sample_rate = torchaudio.load(filename)\\n  mel = t(waveform)\\n  mel_l.append(mel.shape[2])\\n  wav_l.append(waveform.shape[1])\\n  i+=1\\n  if i%100 == 0:\\n    print(i)\\n\\ndf[\"mel_l\"] = mel_l\\ndf[\"wav_l\"] = wav_l\\nnew_TSV = \"new_\" + TSV\\ntsvm = os.path.join(\"/content/drive/MyDrive/senior_sound/work\", new_TSV)\\ndf.to_csv(tsvm, sep = \\'\\t\\', index=False)'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"t = torchaudio.transforms.MelSpectrogram(sample_rate=48000, n_mels=128)\n",
    "path = \"/content/COMMONVOICE\"\n",
    "TSV = \"my_test.tsv\"\n",
    "\n",
    "tsvm = os.path.join(path, TSV)\n",
    "df = pd.read_csv(tsvm, sep=\"\\t\")\n",
    "strings = df['path'].values\n",
    "folder = os.path.join(path, \"clips\")\n",
    "\n",
    "mel_l, wav_l = [], []\n",
    "i = 0\n",
    "print(len(strings))\n",
    "for names in strings:\n",
    "  filename = os.path.join(folder,names)\n",
    "  waveform, sample_rate = torchaudio.load(filename)\n",
    "  mel = t(waveform)\n",
    "  mel_l.append(mel.shape[2])\n",
    "  wav_l.append(waveform.shape[1])\n",
    "  i+=1\n",
    "  if i%100 == 0:\n",
    "    print(i)\n",
    "\n",
    "df[\"mel_l\"] = mel_l\n",
    "df[\"wav_l\"] = wav_l\n",
    "new_TSV = \"new_\" + TSV\n",
    "tsvm = os.path.join(\"/content/drive/MyDrive/senior_sound/work\", new_TSV)\n",
    "df.to_csv(tsvm, sep = '\\t', index=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mFXBUJ--qA38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from modules import Model_Check\\nb_model = Model_Check(hyperparams)\\n\\ntext_mask, audio_mask = None, None\\ntext_input = torch.zeros((1, 300)).long()\\naudio_input = torch.randn((1, 1, 128, 1602)).long()\\n\\ninput = (text_input, text_mask, audio_input, audio_mask)\\n\\ny = b_model(text_input, text_mask, audio_input, audio_mask)\\nprint(y.shape)\\nprint(summary(b_model, text_input, text_mask, audio_input, audio_mask, show_input=True))\\nc = 0\\nfor parameter in model.parameters():\\n    print((parameter.shape))\\n    if len(parameter.shape) == 1:\\n      c += parameter.shape[0]\\n    else:\\n      c += (parameter.shape[0] * parameter.shape[1])\\nc'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from modules import Model_Check\n",
    "b_model = Model_Check(hyperparams)\n",
    "\n",
    "text_mask, audio_mask = None, None\n",
    "text_input = torch.zeros((1, 300)).long()\n",
    "audio_input = torch.randn((1, 1, 128, 1602)).long()\n",
    "\n",
    "input = (text_input, text_mask, audio_input, audio_mask)\n",
    "\n",
    "y = b_model(text_input, text_mask, audio_input, audio_mask)\n",
    "print(y.shape)\n",
    "print(summary(b_model, text_input, text_mask, audio_input, audio_mask, show_input=True))\n",
    "c = 0\n",
    "for parameter in model.parameters():\n",
    "    print((parameter.shape))\n",
    "    if len(parameter.shape) == 1:\n",
    "      c += parameter.shape[0]\n",
    "    else:\n",
    "      c += (parameter.shape[0] * parameter.shape[1])\n",
    "c\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "n1oxwUhgDHkH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"cp\" не является внутренней или внешней\n",
      "командой, исполняемой программой или пакетным файлом.\n",
      "\"cp\" не является внутренней или внешней\n",
      "командой, исполняемой программой или пакетным файлом.\n",
      "\"unzip\" не является внутренней или внешней\n",
      "командой, исполняемой программой или пакетным файлом.\n"
     ]
    }
   ],
   "source": [
    "#!wget -c https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-5.1-2020-06-22/en.tar.gz -P\"drive/My Drive/senior_sound/work\"\n",
    "#!tar -xf \"drive/My Drive/senior_sound/work/en.tar.gz\" -C \"drive/My Drive/senior_sound/work/COMMONVOICE\"\n",
    "!mkdir COMMONVOICE\n",
    "!cp \"/content/drive/MyDrive/senior_sound/work/c_en_sound.zip\" \"/content/COMMONVOICE\"\n",
    "!cp /content/drive/MyDrive/senior_sound/work/{ph_end_new_my_train.tsv,ph_end_new_my_test.tsv,ph_end_new_my_dev.tsv} /content/COMMONVOICE\n",
    "!unzip -n -q \"/content/COMMONVOICE/c_en_sound.zip\" -d \"/content/COMMONVOICE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOi_5MFcN5ht"
   },
   "outputs": [],
   "source": [
    "!mkdir lj\n",
    "!cp \"/content/drive/MyDrive/senior_sound/work/lj/wavs.zip\" \"/content/lj\"\n",
    "!cp /content/drive/MyDrive/senior_sound/work/lj/data.tsv /content/lj\n",
    "!unzip -n -q \"/content/lj/wavs.zip\" -d \"/content/lj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V6mypqk5d_oR"
   },
   "outputs": [],
   "source": [
    "!pip install librosa\n",
    "!pip install torchaudio #-f https://download.pytorch.org/whl/torch_stable.html\n",
    "#!pip install https://github.com/PytorchLightning/pytorch-lightning/archive/0.9.0.zip --upgrade\n",
    "!pip install pytorch-model-summary\n",
    "!pip install allennlp\n",
    "!pip install phonemizer\n",
    "!apt-get install festival espeak-ng mbrola\n",
    "!pip install pytorch-lightning\n",
    "!pip install comet-ml\n",
    "!pip install local-attention\n",
    "!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvzGlCkCe8_4"
   },
   "outputs": [],
   "source": [
    "from hparams import hyperparams\n",
    "hyperparams.path_dataset_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0wTbWx5wfzPY"
   },
   "outputs": [],
   "source": [
    "from depen import *\n",
    "from model import Multi_Synth_pl\n",
    "from datasets import Common_pl_dataset\n",
    "\n",
    "from pytorch_model_summary import summary\n",
    "from comet_ml import Experiment\n",
    "from pytorch_lightning.loggers import CometLogger\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from ljdatasets import Lj_pl_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWJL1HMKFQ9K"
   },
   "outputs": [],
   "source": [
    "class CheckpointEveryNSteps(pl.Callback):\n",
    "    \"\"\"\n",
    "    Save a checkpoint every N steps, instead of Lightning's default that checkpoints\n",
    "    based on validation loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        save_step_frequency,\n",
    "        prefix=\"N-Step-Checkpoint\",\n",
    "        use_modelcheckpoint_filename=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            save_step_frequency: how often to save in steps\n",
    "            prefix: add a prefix to the name, only used if\n",
    "                use_modelcheckpoint_filename=False\n",
    "            use_modelcheckpoint_filename: just use the ModelCheckpoint callback's\n",
    "                default filename, don't use ours.\n",
    "        \"\"\"\n",
    "        self.save_step_frequency = save_step_frequency\n",
    "        self.prefix = prefix\n",
    "        self.use_modelcheckpoint_filename = use_modelcheckpoint_filename\n",
    "\n",
    "    def on_batch_end(self, trainer: pl.Trainer, _):\n",
    "        \"\"\" Check if we should save a checkpoint after every train batch \"\"\"\n",
    "        epoch = trainer.current_epoch\n",
    "        global_step = trainer.global_step\n",
    "        if global_step % self.save_step_frequency == 0:\n",
    "            if self.use_modelcheckpoint_filename:\n",
    "                filename = trainer.checkpoint_callback.filename\n",
    "            else:\n",
    "                filename = f\"{self.prefix}_{epoch}_{global_step}.ckpt\"\n",
    "            ckpt_path = os.path.join(trainer.checkpoint_callback.dirpath, filename)\n",
    "            trainer.save_checkpoint(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gmz_3499b9B8"
   },
   "outputs": [],
   "source": [
    "seed_e(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dk8MaLRcZByb"
   },
   "outputs": [],
   "source": [
    "comet_logger = CometLogger(\n",
    "    save_dir='/content/log/',\n",
    "    api_key=\"23CU99n7TeyZdPeegNDlQ5aHf\",\n",
    "    project_name=\"sound-proj\",\n",
    "    workspace=\"etzelkut\",\n",
    "    # rest_api_key=os.environ[\"COMET_REST_KEY\"], # Optional\n",
    "    # experiment_name=\"default\" # Optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xkCbUmxxbGJ4"
   },
   "outputs": [],
   "source": [
    "dataset_pl = Lj_pl_dataset(hyperparams)\n",
    "dataset_pl.prepare_data()\n",
    "dataset_pl.setup()\n",
    "train_loader = dataset_pl.train_dataloader()\n",
    "steps_per_epoch = int(len(train_loader))\n",
    "print(steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTn1IxCAqDs2"
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "                                      monitor='val_loss',\n",
    "                                      save_last=True, \n",
    "                                      dirpath= \"/content/drive/MyDrive/senior_sound/gg/\",#os.path.join(path, \"/checkpoints\"),\n",
    "                                      filename='samplemodel{epoch}.ckpt',\n",
    "                                      save_top_k=3,\n",
    "                                      mode='min',\n",
    "                                      )\n",
    "every_epoch = CheckpointEveryNSteps(save_step_frequency = steps_per_epoch, use_modelcheckpoint_filename = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZyBADabaPqm"
   },
   "outputs": [],
   "source": [
    "model = Multi_Synth_pl(hyperparams, steps_per_epoch = steps_per_epoch)\n",
    "#lr_monitor = LearningRateMonitor(logging_interval='step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1FS8e_CobEuE"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(callbacks=[checkpoint_callback, every_epoch], #lr_monitor],\n",
    "                    logger=comet_logger,\n",
    "                    gpus=1,\n",
    "                    profiler=True,\n",
    "                    #auto_lr_find=True, #set hparams\n",
    "                    #gradient_clip_val=0.5,\n",
    "                    check_val_every_n_epoch=5,\n",
    "                    #early_stop_callback=True,\n",
    "                    max_epochs = hyperparams.epochs,\n",
    "                    #min_epochs=400,\n",
    "                    progress_bar_refresh_rate = 0,\n",
    "                    deterministic=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o5ujpbBIahB3"
   },
   "outputs": [],
   "source": [
    "trainer.fit(model, dataset_pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4O56mL6OMfYk"
   },
   "outputs": [],
   "source": [
    "checkpoint_name = os.path.join(\"/content/drive/MyDrive/senior_sound/gg\", 'manual_save' + str(228) + '.ckpt')\n",
    "trainer.save_checkpoint(checkpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cKo8m3QgcFL_"
   },
   "outputs": [],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HH7P1iPBLzlw"
   },
   "outputs": [],
   "source": [
    "#################"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "sound_proj.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
